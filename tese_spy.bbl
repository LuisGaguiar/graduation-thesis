\providecommand{\abntreprintinfo}[1]{%
 \citeonline{#1}}
\setlength{\labelsep}{0pt}\begin{thebibliography}{}
\providecommand{\abntrefinfo}[3]{}
\providecommand{\abntbstabout}[1]{}
\abntbstabout{1.45.2.1 }

\bibitem[Abdolmaleki \textit{et al.} 2016]{abbas}
\abntrefinfo{Abdolmaleki \textit{et al.}}{ABDOLMALEKI \textit{et al.}}{2016}
{ABDOLMALEKI, A.; SIMÕES, D.; LAU, N.; NEUMANN, L. P.~R. andGerhard. Learning
  a humanoid kick with controlled distance.
\textbf{20th RoboCup International Symposium, Leipzig, Germany, July 2016.},
  July 2016.}

\bibitem[Barto \textit{et al.} 1983]{TDLearning}
\abntrefinfo{Barto \textit{et al.}}{BARTO \textit{et al.}}{1983}
{BARTO, A.~G.; SUTTON, R.~S.; ANDERSON, C.~W. Neuronlike adaptive elements that
  can solve difficult learning control problems.
1983.}

\bibitem[Bengio \textit{et al.} 2009]{BengioCurrLearning}
\abntrefinfo{Bengio \textit{et al.}}{BENGIO \textit{et al.}}{2009}
{BENGIO, Y.; LOURADOUR, J.; COLLOBERT, R.; WESTON, J. Curriculum learning. In:
  \textbf{Proceedings of the 26th Annual International Conference on Machine
  Learning}. New York, NY, USA: ACM, 2009.  (ICML '09), p. 41--48.
ISBN 978-1-60558-516-1. Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/doi\-.acm\-.org\-/10\-.1145\-/1553374\-.1553380$>$}{http://doi.acm.org/10.1145/1553374.1553380}.}

\bibitem[Heess \textit{et al.} 2017]{deepmind1}
\abntrefinfo{Heess \textit{et al.}}{HEESS \textit{et al.}}{2017}
{HEESS, N.; TB, D.; SRIRAM, S.; LEMMON, J.; MEREL, J.; WAYNE, G.; TASSA, Y.;
  EREZ, T.; WANG, Z.; ESLAMI, S. M.~A.; RIEDMILLER, M.; SILVER, D. Emergence of
  locomotion behaviours in rich environments.
july 2017.}

\bibitem[Ho e Ermon 2016]{gail}
\abntrefinfo{Ho e Ermon}{HO; ERMON}{2016}
{HO, J.; ERMON, S. Generative adversarial imitation learning. In:
  \textbf{Advances in Neural Information Processing Systems}. [S.l.: s.n.],
  2016. p. 4565–4573.}

\bibitem[Lillicrap \textit{et al.} 2015]{DDPG}
\abntrefinfo{Lillicrap \textit{et al.}}{LILLICRAP \textit{et al.}}{2015}
{LILLICRAP, T.~P.; HUNT, J.~J.; PRITZEL, A.; HEESS, N.; EREZ, T.; TASSA, Y.;
  SILVER, D.; WIERSTRA, D. Continuous control with deep reinforcement learning.
\textbf{CoRR}, abs/1509.02971, 2015.
Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/arxiv\-.org\-/abs\-/1509\-.02971$>$}{http://arxiv.org/abs/1509.02971}.}

\bibitem[Lin 1992]{ReplayBuffer}
\abntrefinfo{Lin}{LIN}{1992}
{LIN, L.-J. Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
1992.}

\bibitem[Marr]{AIapplications}
\abntrefinfo{Marr}{MARR}{}
{MARR, B. \textbf{The Top 10 AI And Machine Learning Use Cases Everyone Should
  Know About}.
Dispon{\'\i}vel em:
  $<$https:\-/\-/www\-.forbes\-.com\-/sites\-/bernardmarr\-/2016\-/09\-/30\-/what-are-the-top-10-use-cases-for-machine-learning-and-ai\-/#1b87569994c9$>$.}

\bibitem[Merel \textit{et al.} 2017]{deepmind2}
\abntrefinfo{Merel \textit{et al.}}{MEREL \textit{et al.}}{2017}
{MEREL, J.; TASSA, Y.; TB, D.; SRINIVASAN, S.; LEMMON, J.; WANG, Z.; WAYNE, G.;
  HEESS, N. Learning human behaviors from motion capture by adversarial
  imitation.
july 2017.}

\bibitem[Mnih \textit{et al.} 2015]{RLNature2015}
\abntrefinfo{Mnih \textit{et al.}}{MNIH \textit{et al.}}{2015}
{MNIH, V.; KAVUKCUOGLU, K.; SILVER, D.; RUSU, A.~A.; VENESS, J.; BELLEMARE,
  M.~G.; GRAVES, A.; RIEDMILLER, M.; FIDJELAND, A.~K.; OSTROVSKI, G.; PETERSEN,
  S.; BEATTIE, C.; SADIK, A.; ANTONOGLOU, I.; KING, H.; KUMARAN, D.; WIERSTRA,
  D.; LEGG, S.; HASSABIS, D. Human-level control through deep reinforcement
  learning.
\textbf{Nature}, Nature Publishing Group, a division of Macmillan Publishers
  Limited. All Rights Reserved., v.~518, n.~7540, p. 529--533, Feb 2015.
ISSN 0028-0836.
Letter.
Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/dx\-.doi\-.org\-/10\-.1038\-/nature14236$>$}{http://dx.doi.org/10.1038/nature14236}.}

\bibitem[Peng \textit{et al.} 2018]{deepmimic}
\abntrefinfo{Peng \textit{et al.}}{PENG \textit{et al.}}{2018}
{PENG, X.~B.; ABBEEL, P.; LEVINE, S.; PANNE, M. V.~D. Deepmimic: Example-guided
  deep reinforcement learning of physics-based character skills.
April 2018.}

\bibitem[Schulman \textit{et al.} 2015]{TRPO}
\abntrefinfo{Schulman \textit{et al.}}{SCHULMAN \textit{et al.}}{2015}
{SCHULMAN, J.; LEVINE, S.; MORITZ, P.; JORDAN, M.~I.; ABBEEL, P. Trust region
  policy optimization.
\textbf{CoRR}, abs/1502.05477, 2015.
Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/arxiv\-.org\-/abs\-/1502\-.05477$>$}{http://arxiv.org/abs/1502.05477}.}

\bibitem[Schulman \textit{et al.} 2017]{PPO}
\abntrefinfo{Schulman \textit{et al.}}{SCHULMAN \textit{et al.}}{2017}
{SCHULMAN, J.; WOLSKI, F.; DHARIWAL, P.; RADFORD, A.; KLIMOV, O. Proximal
  policy optimization algorithms.
\textbf{CoRR}, abs/1707.06347, 2017.
Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/arxiv\-.org\-/abs\-/1707\-.06347$>$}{http://arxiv.org/abs/1707.06347}.}

\bibitem[Silver]{lecture1DS}
\abntrefinfo{Silver}{SILVER}{}
{SILVER, D. \textbf{Lecture 1: Introduction to Reinforcement Learning}.
Dispon{\'\i}vel em:
  \htmladdnormallink{$<$http:\-/\-/www0\-.cs\-.ucl\-.ac\-.uk\-/staff\-/D\-.Silver\-/web\-/Teaching\-.html$>$}{http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html}.
  Acesso em: 25 Junho de 2018.}

\bibitem[Silver \textit{et al.} 2017]{AlphaGoZero}
\abntrefinfo{Silver \textit{et al.}}{SILVER \textit{et al.}}{2017}
{SILVER, D.; SCHRITTWIESER, J.; SIMONYAN, K.; ANTONOGLOU, I.; HUANG, A.; GUEZ,
  A.; HUBERT, T.; BAKER, L.; LAI, M.; BOLTON, A.; CHEN, Y.; LILLICRAP, T.; HUI,
  F.; SIFRE, L.; DRIESSCHE, G. van~den; GRAEPEL, T.; HASSABIS, D. Mastering the
  game of go without human knowledge.
\textbf{Nature}, Macmillan Publishers Limited, part of Springer Nature. All
  rights reserved., v.~550, out. 2017.}

\bibitem[Sutton e Barto 1998]{Sutton1998}
\abntrefinfo{Sutton e Barto}{SUTTON; BARTO}{1998}
{SUTTON, R.~S.; BARTO, A.~G. \textbf{Introduction to Reinforcement Learning}.
  1st. ed. Cambridge, MA, USA: MIT Press, 1998.
ISBN 0262193981.}

\bibitem[Wang \textit{et al.} 2017]{deepmind3}
\abntrefinfo{Wang \textit{et al.}}{WANG \textit{et al.}}{2017}
{WANG, Z.; MEREL, J.; REED, S.; WAYNE, G.; FREITAS, N. de; HEESS, N. Robust
  imitation of diverse behaviors.
july 2017.}

\bibitem[Watkins 1989]{QLearning}
\abntrefinfo{Watkins}{WATKINS}{1989}
{WATKINS, C. J. C.~H.
\textbf{Learning from Delayed Rewards}.
Tese (Doutorado) --- King's College, 1989.}

\bibitem[Wiliams 1992]{REINFORCE}
\abntrefinfo{Wiliams}{WILIAMS}{1992}
{WILIAMS, R.~J. Simple statistical gradient-following algorithms for
  connectionist reinforcement learning.
1992.}

\end{thebibliography}
